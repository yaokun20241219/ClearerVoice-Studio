{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的库\n",
    "导入项目中使用的所有必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库/引用\n",
    "from clearvoice import ClearVoice  # Import the ClearVoice class for speech processing tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo One: Using a Single Model\n",
    "运行一个模型\n",
    "\n",
    "第三种调用方法：在这个上下文中，`.scp`文件是一种脚本文件，用于列出多个音频文件的路径。`.scp`文件通常用于批量处理音频文件，文件中每一行包含一个音频文件的路径。\n",
    "\n",
    "例如，`audio_samples.scp` 文件的内容可能如下：\n",
    "```python\n",
    "samples/input1.wav \n",
    "samples/input2.wav \n",
    "samples/input3.wav\n",
    "```\n",
    "在代码中，`myClearVoice`对象使用这个`.scp`文件来读取多个音频文件的路径，并对这些音频文件进行处理。需要注意的是，这里的`.scp`文件与Secure Copy Protocol（SCP）无关，它只是一个简单的文本文件，用于列出文件路径。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n",
      "Running MossFormer2_SE_48K ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m myClearVoice \u001b[38;5;241m=\u001b[39m ClearVoice(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech_enhancement\u001b[39m\u001b[38;5;124m'\u001b[39m, model_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMossFormer2_SE_48K\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1st calling method: \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#   Process an input waveform and return the enhanced output waveform\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# - input_path (str): Path to the input noisy audio file (input.wav)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# - output_wav (dict or ndarray) : The enhanced output waveform\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m output_wav \u001b[38;5;241m=\u001b[39m \u001b[43mmyClearVoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamples/input.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Write the processed waveform to an output file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# - output_path (str): Path to save the enhanced audio file (output_MossFormer2_SE_48K.wav)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m myClearVoice\u001b[38;5;241m.\u001b[39mwrite(output_wav, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples/output_MossFormer2_SE_48K.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/clearvoice.py:41\u001b[0m, in \u001b[0;36mClearVoice.__call__\u001b[0;34m(self, input_path, online_write, output_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m---> 41\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monline_write\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m online_write:\n\u001b[1;32m     43\u001b[0m         results[model\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/networks.py:236\u001b[0m, in \u001b[0;36mSpeechModel.process\u001b[0;34m(self, input_path, online_write, output_path)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_len\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_len\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Perform the audio decoding/processing\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m output_audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Perform audio renormalization\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_audio, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/networks.py:172\u001b[0m, in \u001b[0;36mSpeechModel.decode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mDecodes the input audio data using the loaded model and ensures the output matches the original audio length.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m          If multi-speaker audio is processed, a list of truncated audio outputs per speaker is returned.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Decode the audio using the loaded model on the given device (e.g., CPU or GPU)\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m output_audio \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_one_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Ensure the decoded output matches the length of the input audio\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_audio, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# If multi-speaker audio (a list of outputs), truncate each speaker's audio to input length\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/utils/decode.py:39\u001b[0m, in \u001b[0;36mdecode_one_audio\u001b[0;34m(model, device, inputs, args)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decode_one_audio_frcrn_se_16k(model, device, inputs, args)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMossFormer2_SE_48K\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_one_audio_mossformer2_se_48k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMossFormerGAN_SE_16K\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decode_one_audio_mossformergan_se_16k(model, device, inputs, args)\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/utils/decode.py:419\u001b[0m, in \u001b[0;36mdecode_one_audio_mossformer2_se_48k\u001b[0;34m(model, device, inputs, args)\u001b[0m\n\u001b[1;32m    416\u001b[0m fbanks \u001b[38;5;241m=\u001b[39m fbanks\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Add batch dimension and move to device\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# Pass filter banks through the model\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m Out_List \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfbanks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m pred_mask \u001b[38;5;241m=\u001b[39m Out_List[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Get the predicted mask\u001b[39;00m\n\u001b[1;32m    421\u001b[0m spectrum \u001b[38;5;241m=\u001b[39m stft(audio, args)  \u001b[38;5;66;03m# Apply STFT to the audio\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/models/mossformer2_se/mossformer2_se_wrapper.py:95\u001b[0m, in \u001b[0;36mTestNet.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Change shape from [B, N, S] to [B, S, N]\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Get the mask from the MossFormer MaskNet\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmossformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass through the MossFormer_MaskNet\u001b[39;00m\n\u001b[1;32m     96\u001b[0m out_list\u001b[38;5;241m.\u001b[39mappend(mask)  \u001b[38;5;66;03m# Append the mask to the output list\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Development/open_source/AI/ClearerVoice-Studio/clearvoice/models/mossformer2_se/mossformer2.py:608\u001b[0m, in \u001b[0;36mMossFormer_MaskNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the output tensor.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03mArguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    (speakers) and is ordered such that the first index corresponds to the target speech.\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;66;03m# Normalize the input\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# [B, N, L]\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Apply encoder convolution\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# [B, N, L]\u001b[39;00m\n\u001b[1;32m    612\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_encoder(x)\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/nn/modules/normalization.py:273\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/nn/functional.py:2530\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2529\u001b[0m _verify_batch_size([\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:]))\n\u001b[0;32m-> 2530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/T9/system/anaconda3/envs/ClearerVoice-Studio/lib/python3.8/site-packages/torch/_refs/__init__.py:2968\u001b[0m, in \u001b[0;36mnative_group_norm\u001b[0;34m(input, weight, bias, batch_size, num_channels, flattened_inner_size, num_groups, eps)\u001b[0m\n\u001b[1;32m   2965\u001b[0m     unsqueeze_weight \u001b[38;5;241m=\u001b[39m _unsqueeze_multiple(weight, broadcast_dims)\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsqueeze_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2968\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43munsqueeze_weight\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsqueeze_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2970\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m unsqueeze_bias\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# This block demonstrates how to use a single model for speech enhancement\n",
    "# Initialize ClearVoice for the task of speech enhancement using the MossFormer2_SE_48K model\n",
    "myClearVoice = ClearVoice(task='speech_enhancement', model_names=['MossFormer2_SE_48K'])\n",
    "\n",
    "# 1st calling method: \n",
    "#   Process an input waveform and return the enhanced output waveform\n",
    "# - input_path (str): Path to the input noisy audio file (input.wav)\n",
    "# - output_wav (dict or ndarray) : The enhanced output waveform\n",
    "output_wav = myClearVoice(input_path='samples/input.wav')\n",
    "# Write the processed waveform to an output file\n",
    "# - output_path (str): Path to save the enhanced audio file (output_MossFormer2_SE_48K.wav)\n",
    "myClearVoice.write(output_wav, output_path='samples/output_MossFormer2_SE_48K.wav')\n",
    "\n",
    "# 2nd calling method: \n",
    "#   Process and write audio files directly\n",
    "# - input_path (str): Path to the directory of input noisy audio files\n",
    "# - online_write (bool): Set to True to enable saving the enhanced audio directly to files during processing\n",
    "# - output_path (str): Path to the directory to save the enhanced output files\n",
    "myClearVoice(input_path='samples/path_to_input_wavs', online_write=True, output_path='samples/path_to_output_wavs')\n",
    "\n",
    "# 3rd calling method: \n",
    "#   Use an .scp file to specify input audio paths\n",
    "# - input_path (str): Path to a .scp file listing multiple audio file paths\n",
    "# - online_write (bool): Set to True to enable saving the enhanced audio directly to files during processing\n",
    "# - output_path (str): Path to the directory to save the enhanced output files\n",
    "myClearVoice(input_path='samples/scp/audio_samples.scp', online_write=True, output_path='samples/path_to_output_wavs_scp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Two: Using Multiple Models\n",
    "使用多个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block demonstrates how to use multiple models for speech enhancement\n",
    "# Initialize ClearVoice for the task of speech enhancement using two models: MossFormer2_SE_48K and FRCRN_SE_16K\n",
    "myClearVoice = ClearVoice(task='speech_enhancement', model_names=['MossFormer2_SE_48K', 'FRCRN_SE_16K'])\n",
    "\n",
    "# 1st calling method: \n",
    "#   Process an input waveform using the multiple models and return the enhanced output waveform\n",
    "# - input_path (str): Path to the input noisy audio file (input.wav)\n",
    "# - output_wav (dict or ndarray) : The returned output waveforms after being processed by the models\n",
    "output_wav = myClearVoice(input_path='samples/input.wav')\n",
    "# Write the processed waveform to an output file\n",
    "# - output_path (str): Path to the directory to save the enhanced audio file using the same file name as input (input.wav)\n",
    "myClearVoice.write(output_wav, output_path='samples/path_to_output_wavs')\n",
    "\n",
    "# 2nd calling method: \n",
    "#   Process and write audio files directly using multiple models\n",
    "# - input_path (str): Path to the directory of input noisy audio files\n",
    "# - online_write (bool): Set to True to enable saving the enhanced audio directly to files during processing\n",
    "# - output_path (str): Path to the directory to save the enhanced output files\n",
    "myClearVoice(input_path='samples/path_to_input_wavs', online_write=True, output_path='samples/path_to_output_wavs')\n",
    "\n",
    "# 3rd calling method: \n",
    "#   Use an .scp file to specify input audio paths for multiple models\n",
    "# - input_path (str): Path to a .scp file listing multiple audio file paths\n",
    "# - online_write (bool): Set to True to enable saving the enhanced output during processing\n",
    "# - output_path (str): Path to the directory to save the enhanced output files\n",
    "myClearVoice(input_path='samples/scp/audio_samples.scp', online_write=True, output_path='samples/path_to_output_wavs_scp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClearerVoice-Studio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
