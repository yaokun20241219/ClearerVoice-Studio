## Config file

# Log 
seed: 777
use_cuda: 1           # 1 for True, 0 for False

# dataset
speaker_no: 2
mix_lst_path: ./data/YGD/mixture_data_list_2mix.csv
audio_direc: /mnt/nas_sg/mit_sg/zexu.pan/datasets/gesture_TED/audio_clean/
reference_direc: /mnt/nas_sg/mit_sg/zexu.pan/datasets/gesture_TED/visual/gesture_embedding/
audio_sr: 16000
ref_sr: 15

# dataloader
num_workers: 4
batch_size: 8          # 2-GPU training with a total effective batch size of 32
accu_grad: 1
effec_batch_size: 16   # per GPU, only used if accu_grad is set to 1, must be multiple times of batch size
max_length: 10         # truncate the utterances in dataloader, in seconds 

# network settings
init_from: None       # 'None' or a log name 'log_2024-07-22(18:12:13)'
causal: 0             # 1 for True, 0 for False
network_reference:
  cue: gesture            # lip or speech or gesture or EEG
network_audio:
  backbone: seg
  N: 256
  L: 40
  B: 64
  H: 128
  K: 100
  R: 6

# optimizer
loss_type: sisdr      # "snr", "sisdr", "hybrid"
init_learning_rate: 0.0005
max_epoch: 200
clip_grad_norm: 5
